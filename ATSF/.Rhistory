dim(df)[1]
len_before <- dim(df)[1]
# Entferne NA-Werte
df <- na.omit(df)
len_after <- dim(df[1])
len_before - len_after
len_after
len_before
len_after <- dim(df)[1]
len_before - len_after
# Geometrische Kumulation der Renditen
df <- df %>%
mutate(Overnight_Strategy = 100 * (cumprod(1 + Overnight_Return) - 1),
Intraday_Strategy = 100 * (cumprod(1 + Intraday_Return) - 1),
Buy_Hold_Strategy = 100 * (cumprod(1 + Daily_Return) - 1))
dim(df)[1]
# head(df)
par(mfrow=c(1,2))
plot(df$Open, col=1, main="Open")
plot(df$Close, col=2, main="Close")
# head(df)
par(mfrow=c(2,1))
plot(df$Open, col=1, main="Open")
plot(df$Close, col=2, main="Close")
par(mfrow=c(1,1))
par(mfrow=c(1,1))
plot(diff(log(df$Close)), col=3, main="Log-returns")
ts.plot(diff(log(df$Close)), col=3, main="Log-returns")
x_fit<-as.ts(na.omit(diff(log(df$Close))))
# GARCH(1,1)
y.garch_11<-garchFit(~garch(1,1),data=x_fit,delta=2,include.delta=F,include.mean=F,trace=F)
ts.plot(x_fit)
lines(y.garch_11@sigma.t,col="red")
#-----------------
# 2.b
standard_residuals<-y.garch_11@residuals/y.garch_11@sigma.t
ts.plot(standard_residuals)
#-----------------
# 2.c
par(mfrow=c(2,1))
acf(x_fit,main="Acf log-returns",ylim=c(0,0.1))
acf(standard_residuals,main="Acf standardized residuals GARCH(1,1)",ylim=c(0,0.1))
head(df)
head(df)
tail(df)
dim(df)
df[4050,:]
df[4050,]
df[1,]
df[0,]
df[4050,]
install.packages("xts")
library(xts)
# Specify target and explanatory data: we use first 12 lags based on above data analysis
#
x<-na.omit(diff(log(df$Close)))
data_mat <- cbind(
x,
stats::lag(x, -1),
stats::lag(x, -2),
stats::lag(x, -3),
stats::lag(x, -4),
stats::lag(x, -5),
stats::lag(x, -6),
stats::lag(x, -7),
stats::lag(x, -8),
stats::lag(x, -9),
stats::lag(x, -10),
stats::lag(x, -11),
stats::lag(x, -12)
)
# Check length of time series before na.exclude
dim(data_mat)
data_mat<-na.exclude(data_mat)
# Check length of time series after removal of NAs
dim(data_mat)
head(data_mat)
tail(data_mat)
head(df)
rownames(df) <- df[,1]
# Remove the first column since it's now used as row names
df <- df[,-1]
head(df)
x<-na.omit(diff(log(df$Close)))
data_mat <- cbind(
x,
stats::lag(x, -1),
stats::lag(x, -2),
stats::lag(x, -3),
stats::lag(x, -4),
stats::lag(x, -5),
stats::lag(x, -6),
stats::lag(x, -7),
stats::lag(x, -8),
stats::lag(x, -9),
stats::lag(x, -10),
stats::lag(x, -11),
stats::lag(x, -12)
)
# Check length of time series before na.exclude
dim(data_mat)
data_mat<-na.exclude(data_mat)
# Check length of time series after removal of NAs
dim(data_mat)
head(data_mat)
tail(data_mat)
# Check length of time series before na.exclude
dim(data_mat)
data_mat<-na.exclude(data_mat)
# Check length of time series after removal of NAs
dim(data_mat)
head(data_mat)
tail(data_mat)
# Specify in- and out-of-sample episodes
dim(df)
# Specify in- and out-of-sample episodes
dim(df)[1]/2
# Specify in- and out-of-sample episodes
round(dim(df)[1]/2)
# Specify in- and out-of-sample episodes
df[round(dim(df)[1]/2),]
# Specify in- and out-of-sample episodes
row.names(df[round(dim(df)[1]/2),])
# Specify in- and out-of-sample episodes
in_out_sample_separator <- row.names(df[round(dim(df)[1]/2),]) # "2009-02-27"
target_in<-data_mat[paste("/",in_out_sample_separator,sep=""),1]
rownames(data_mat) <- rownames(df)
head(df)
stats::lag(x, -1)[1]
stats::lag(x, -1)[2]
x[1:10]
stats::lag(x, -8)
load(paste(path.dat,"/bitcoin.Rdata",sep=""))
#-------------------
# 1.b
head(dat)
tail(dat)
x<-na.omit(diff(log(dat$Bid)))
head(x)
data_mat <- cbind(
x,
stats::lag(x, -1),
stats::lag(x, -2),
stats::lag(x, -3),
stats::lag(x, -4),
stats::lag(x, -5),
stats::lag(x, -6)
)
head(x)
head(data_mat)
typeof(dat)
typeof(x)
symbol <- "SPY"
getSymbols(symbol, src = "yahoo", from = "1993-01-01", to = Sys.Date(), auto.assign = TRUE)
df <- get(symbol)
head(df)
# Erstelle Dataframe mit relevanten Spalten
df <- data.frame(Date = index(df),
Open = as.numeric(Op(df)),
Close = as.numeric(Cl(df)))
# Berechne Renditen für alle drei Strategien
df <- df %>%
mutate(Overnight_Return = (Open / lag(Close)) - 1,   # Rendite: Buy Close, Sell Next Open
Intraday_Return = (Close / Open) - 1,         # Rendite: Buy Open, Sell Close
Daily_Return = (Close / lag(Close)) - 1)      # Rendite: Buy and Hold (tägliche Rendite)
len_before <- dim(df)[1]
# Entferne NA-Werte
df <- na.omit(df)
len_after <- dim(df)[1]
# number of removed rows
len_before - len_after
# Geometrische Kumulation der Renditen
df <- df %>%
mutate(Overnight_Strategy = 100 * (cumprod(1 + Overnight_Return) - 1),
Intraday_Strategy = 100 * (cumprod(1 + Intraday_Return) - 1),
Buy_Hold_Strategy = 100 * (cumprod(1 + Daily_Return) - 1))
rownames(df) <- df[,1]
# Remove the first column since it's now used as row names
df <- df[,-1]
head(df)
x<-na.omit(diff(log(df$Close)))
head(x)
typeof(x)
class(x)
#-------------------
# 1.b
head(dat)
class(dat)
head(df)
df <- get(symbol)
# Erstelle Dataframe mit relevanten Spalten
df <- data.frame(Date = index(df),
Open = as.numeric(Op(df)),
Close = as.numeric(Cl(df)))
# Berechne Renditen für alle drei Strategien
df <- df %>%
mutate(Overnight_Return = (Open / lag(Close)) - 1,   # Rendite: Buy Close, Sell Next Open
Intraday_Return = (Close / Open) - 1,         # Rendite: Buy Open, Sell Close
Daily_Return = (Close / lag(Close)) - 1)      # Rendite: Buy and Hold (tägliche Rendite)
len_before <- dim(df)[1]
# Entferne NA-Werte
df <- na.omit(df)
len_after <- dim(df)[1]
# number of removed rows
len_before - len_after
# Geometrische Kumulation der Renditen
df <- df %>%
mutate(Overnight_Strategy = 100 * (cumprod(1 + Overnight_Return) - 1),
Intraday_Strategy = 100 * (cumprod(1 + Intraday_Return) - 1),
Buy_Hold_Strategy = 100 * (cumprod(1 + Daily_Return) - 1))
spy_xts <- xts(df[, -1], order.by = df$Date)
# Remove the first column since it's now used as row names
# df <- df[,-1]
head(df)
head(spy_xts)
head(x)
x<-na.omit(diff(log(spy_xts$Close)))
head(x)
data_mat <- cbind(
x,
stats::lag(x, -1),
stats::lag(x, -2),
stats::lag(x, -3),
stats::lag(x, -4),
stats::lag(x, -5),
stats::lag(x, -6),
stats::lag(x, -7),
stats::lag(x, -8),
stats::lag(x, -9),
stats::lag(x, -10),
stats::lag(x, -11),
stats::lag(x, -12)
)
head(x)
head(data_mat)
# Check length of time series before na.exclude
dim(data_mat)
data_mat<-na.exclude(data_mat)
# Check length of time series after removal of NAs
dim(data_mat)
head(data_mat)
tail(data_mat)
# Specify in- and out-of-sample episodes
in_out_sample_separator <- row.names(df[round(dim(df)[1]/2),]) # "2009-02-27"
in_out_sample_separator
round(dim(df)[1]/2)
df[round(dim(df)[1]/2),]
df[round(dim(df)[1]/2),1]
# Specify in- and out-of-sample episodes
in_out_sample_separator <- df[round(dim(df)[1]/2),1] # "2009-02-27"
in_out_sample_separator
target_in<-data_mat[paste("/",in_out_sample_separator,sep=""),1]
tail(target_in)
explanatory_in<-data_mat[paste("/",in_out_sample_separator,sep=""),2:ncol(data_mat)]
tail(explanatory_in)
target_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),1]
head(target_out)
tail(target_out)
explanatory_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),2:ncol(data_mat)]
nrow(test)
train<-cbind(target_in,explanatory_in)
test<-cbind(target_out,explanatory_out)
head(test)
tail(test)
nrow(train)
nrow(test)
# Check length of time series after removal of NAs
dim(data_mat)
round(dim(data_mat)[1]/2)
data_mat[round(dim(data_mat)[1]/2),]
rownames(data_mat)[4044]
index(data_mat)[4044]
index(data_mat)[round(dim(data_mat)[1]/2)]
# Specify in- and out-of-sample episodes
in_out_sample_separator <- index(data_mat)[round(dim(data_mat)[1]/2)] # "2009-02-20"
target_in<-data_mat[paste("/",in_out_sample_separator,sep=""),1]
tail(target_in)
explanatory_in<-data_mat[paste("/",in_out_sample_separator,sep=""),2:ncol(data_mat)]
tail(explanatory_in)
target_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),1]
head(target_out)
tail(target_out)
explanatory_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),2:ncol(data_mat)]
train<-cbind(target_in,explanatory_in)
test<-cbind(target_out,explanatory_out)
head(test)
tail(test)
nrow(train)
nrow(test)
maxs <- apply(data_mat, 2, max)
maxs <- apply(data_mat, 2, max)
mins <- apply(data_mat, 2, min)
# Transform data into [0,1]
scaled <- scale(data_mat, center = mins, scale = maxs - mins)
apply(scaled,2,min)
apply(scaled,2,max)
#-----------------
# 4.b
# Train-test split
train_set <- scaled[paste("/",in_out_sample_separator,sep=""),]
test_set <- scaled[paste(in_out_sample_separator,"/",sep=""),]
train_set<-as.matrix(train_set)
test_set<-as.matrix(test_set)
n <- colnames(train_set)
n
colnames(train_set)<-paste("lag",0:(ncol(train_set)-1),sep="")
n <- colnames(train_set)
n
# Model: target is current bitcoin, all other variables are explanatory
f <- as.formula(paste("lag0 ~", paste(n[!n %in% "lag0"], collapse = " + ")))
tail(train_set)
colnames(train_set)
head(f)
# Set/fix the random seed
set.seed(3)
nn <- neuralnet(f,data=train_set,hidden=c(3,2),linear.output=F)
#------------------------------------
# 4.d (compare different realizations of the above net: train the net without specifying set.seed)
plot(nn)
# In sample performance
# 1. Without re-scaling: MSE based on transformed data
MSE.in.nn<-mean(((train_set[,1]-nn$net.result[[1]])*(max(data_mat[,1])-min(data_mat[,1])))^2)
# 2. With re-scaling: MSE based on scale of original data
scaling_term<-(max(data_mat[,1])-min(data_mat[,1]))
MSE.in.nn<-mean(((train_set[,1]-nn$net.result[[1]])*scaling_term)^2)
MSE.in.nn
# Out-of-sample performance
# 1. Compute out-of-sample predictions based on transformed data
# Provide test-data to predict: use explanatory columns 2:ncol(test_set) (First column is forecast target)
pr.nn <- predict(nn,test_set[,2:ncol(test_set)])
predicted_scaled<-pr.nn
# Numbers are between 0 and 1
tail(predicted_scaled)
scaling_term
# Transform forecasts back to original data: rescale and shift by min(data_mat[,1])
predicted_nn <- predicted_scaled*scaling_term+min(data_mat[,1])
test.r <- test_set[,1]*scaling_term+min(data_mat[,1])
# Check: test.r is the same as test[,1]
test[,1]-test.r
# Calculating MSE
MSE.out.nn <- sum((test.r - predicted_nn)^2)/nrow(test_set)
# Compare in-sample and out-of-sample
c(MSE.in.nn,MSE.out.nn)
#--------------------------------
# 4.f Trading performance
perf_nn<-(sign(predicted_nn))*target_out
sharpe_nn<-sqrt(365)*mean(perf_nn,na.rm=T)/sqrt(var(perf_nn,na.rm=T))
perf_nn
sharpe_nn
plot(cumsum(perf_nn),main=paste("NN cumulated performances out-of-sample, sharpe=",round(sharpe_nn,2),sep=""))
par(mfrow=c(1,1))
plot(cumsum(perf_nn),main=paste("NN cumulated performances out-of-sample, sharpe=",round(sharpe_nn,2),sep=""))
head(df)
x_fit<-as.ts(na.omit(diff(log(df$Open))))
# GARCH(1,1)
y.garch_11<-garchFit(~garch(1,1),data=x_fit,delta=2,include.delta=F,include.mean=F,trace=F)
ts.plot(x_fit)
lines(y.garch_11@sigma.t,col="red")
#-----------------
standard_residuals<-y.garch_11@residuals/y.garch_11@sigma.t
ts.plot(standard_residuals)
#-----------------
par(mfrow=c(2,1))
acf(x_fit,main="Acf log-returns",ylim=c(0,0.1))
acf(standard_residuals,main="Acf standardized residuals GARCH(1,1)",ylim=c(0,0.1))
head(x)
x<-na.omit(log(spy_xts$Overnight_Return))
log(0)
dim(spy_xts)
dim(x)
# overnigth-returns strategy
sum(spy_xts$Overnight_Return == 0)
log(-2)
# Erstelle Dataframe mit relevanten Spalten
symbol <- "SPY"
getSymbols(symbol, src = "yahoo", from = "1993-01-01", to = Sys.Date(), auto.assign = TRUE)
df <- get(symbol)
df <- data.frame(Date = index(df),
Open = as.numeric(Op(df)),
Close = as.numeric(Cl(df)))
# Berechne Renditen für alle drei Strategien
df <- df %>%
mutate(Open_log = log(Open),
Close_log = log(Close)) %>%
mutate(Overnight_Return = (Open_log / lag(Close_log)) - 1,   # Rendite: Buy Close, Sell Next Open
Intraday_Return = (Close_log / Open_log) - 1,         # Rendite: Buy Open, Sell Close
Daily_Return = (Close_log / lag(Close_log)) - 1)      # Rendite: Buy and Hold (tägliche Rendite)
len_before <- dim(df)[1]
len_before
# Entferne NA-Werte
df <- na.omit(df)
len_after <- dim(df)[1]
# number of removed rows
len_before - len_after
head(df)
spy_xts <- xts(df[, -1], order.by = df$Date)
dim(spy_xts)
df <- get(symbol)
df <- data.frame(Date = index(df),
Open = as.numeric(Op(df)),
Close = as.numeric(Cl(df)))
# Berechne Renditen für alle drei Strategien
df <- df %>%
mutate(Open_log = log(Open),
Close_log = log(Close)) %>%
mutate(Overnight_log_Return = (Open_log / lag(Close_log)) - 1,   # Rendite: Buy Close, Sell Next Open
Intraday_log_Return = (Close_log / Open_log) - 1,         # Rendite: Buy Open, Sell Close
Daily_log_Return = (Close_log / lag(Close_log)) - 1)      # Rendite: Buy and Hold (tägliche Rendite)
len_before <- dim(df)[1]
# Entferne NA-Werte
df <- na.omit(df)
len_after <- dim(df)[1]
# number of removed rows
len_before - len_after
head(df)
spy_xts <- xts(df[, -1], order.by = df$Date)
dim(spy_xts)
x<-na.omit(spy_xts$Overnight_log_Return)
head(x)
data_mat <- cbind(
x,
stats::lag(x, -1),
stats::lag(x, -2),
stats::lag(x, -3),
stats::lag(x, -4),
stats::lag(x, -5),
stats::lag(x, -6),
stats::lag(x, -7),
stats::lag(x, -8),
stats::lag(x, -9),
stats::lag(x, -10),
stats::lag(x, -11),
stats::lag(x, -12)
)
head(data_mat)
# Check length of time series before na.exclude
dim(data_mat)
data_mat<-na.exclude(data_mat)
# Check length of time series after removal of NAs
dim(data_mat)
head(data_mat)
tail(data_mat)
# Specify in- and out-of-sample episodes
in_out_sample_separator <- index(data_mat)[round(dim(data_mat)[1]/2)] # "2009-02-20"
in_out_sample_separator
target_in<-data_mat[paste("/",in_out_sample_separator,sep=""),1]
tail(target_in)
explanatory_in<-data_mat[paste("/",in_out_sample_separator,sep=""),2:ncol(data_mat)]
tail(explanatory_in)
target_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),1]
head(target_out)
tail(target_out)
explanatory_out<-data_mat[paste(in_out_sample_separator,"/",sep=""),2:ncol(data_mat)]
train<-cbind(target_in,explanatory_in)
test<-cbind(target_out,explanatory_out)
head(test)
tail(test)
nrow(train)
nrow(test)
maxs <- apply(data_mat, 2, max)
mins <- apply(data_mat, 2, min)
# Transform data into [0,1]
scaled <- scale(data_mat, center = mins, scale = maxs - mins)
apply(scaled,2,min)
apply(scaled,2,max)
#-----------------
# 4.b
# Train-test split
train_set <- scaled[paste("/",in_out_sample_separator,sep=""),]
test_set <- scaled[paste(in_out_sample_separator,"/",sep=""),]
train_set<-as.matrix(train_set)
test_set<-as.matrix(test_set)
colnames(train_set)<-paste("lag",0:(ncol(train_set)-1),sep="")
n <- colnames(train_set)
# Model: target is current bitcoin, all other variables are explanatory
f <- as.formula(paste("lag0 ~", paste(n[!n %in% "lag0"], collapse = " + ")))
tail(train_set)
# Set/fix the random seed
set.seed(3)
nn <- neuralnet(f,data=train_set,hidden=c(3,2),linear.output=F)
#------------------------------------
# 4.d (compare different realizations of the above net: train the net without specifying set.seed)
plot(nn)
# In sample performance
# 1. Without re-scaling: MSE based on transformed data
MSE.in.nn<-mean(((train_set[,1]-nn$net.result[[1]])*(max(data_mat[,1])-min(data_mat[,1])))^2)
# 2. With re-scaling: MSE based on scale of original data
scaling_term<-(max(data_mat[,1])-min(data_mat[,1]))
MSE.in.nn<-mean(((train_set[,1]-nn$net.result[[1]])*scaling_term)^2)
# Out-of-sample performance
# 1. Compute out-of-sample predictions based on transformed data
# Provide test-data to predict: use explanatory columns 2:ncol(test_set) (First column is forecast target)
pr.nn <- predict(nn,test_set[,2:ncol(test_set)])
predicted_scaled<-pr.nn
# Numbers are between 0 and 1
tail(predicted_scaled)
# Transform forecasts back to original data: rescale and shift by min(data_mat[,1])
predicted_nn <- predicted_scaled*scaling_term+min(data_mat[,1])
test.r <- test_set[,1]*scaling_term+min(data_mat[,1])
# Check: test.r is the same as test[,1]
test[,1]-test.r
# Calculating MSE
MSE.out.nn <- sum((test.r - predicted_nn)^2)/nrow(test_set)
# Compare in-sample and out-of-sample
c(MSE.in.nn,MSE.out.nn)
#--------------------------------
# 4.f Trading performance
perf_nn<-(sign(predicted_nn))*target_out
sharpe_nn<-sqrt(365)*mean(perf_nn,na.rm=T)/sqrt(var(perf_nn,na.rm=T))
plot(cumsum(perf_nn),main=paste("NN cumulated performances out-of-sample, sharpe=",round(sharpe_nn,2),sep=""))
par(mfrow=c(1,1))
plot(cumsum(perf_nn),main=paste("NN cumulated performances out-of-sample, sharpe=",round(sharpe_nn,2),sep=""))
